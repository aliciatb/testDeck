theme(axis.title = element_text(face="bold",size="16"))
)
print(g + geom_bar(stat='identity') +
labs(title = paste(round(matchPercent*100,1),'% match on Keywords.')) +
labs(x = 'Keyword', y = 'Frequency') +
theme(plot.title = element_text(face="bold",size=18)) +
theme(axis.text.x = element_text(angle=90,face="bold",size="14")) +
theme(axis.text.y = element_text(face="bold",size="14")) +
theme(axis.title = element_text(face="bold",size="16"))
)
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
keywords <- "Data Science unicorn"
clean <- gsub("[^a-zA-Z]", " ", job)
clean <- gsub(" +", " ", clean)
clean <- strsplit(clean," ")
jobTerms <- data.table(term=cbind(tolower(unlist(clean))))
setnames(jobTerms,c("term.V1"),c("term"))
# keep only terms that are not in stop words
jobTerms <- jobTerms[!(jobTerms$term %in% stopTerms$term),]
# calculate frequency of term table
freqTerms <- data.frame(xtabs(formula = ~., data = jobTerms))
dt <- data.table(term=tolower(unlist(strsplit(keywords," "))))
# set default match to zero
dt$match <- 0
# if term is in Job Description, set to 1
dt[dt$term %in% jobTerms$term,match:=1]
# matches
freqTermsMatch <- merge(dt,freqTerms,by="term")
# see what % of keywords matched the job description
matchCount <- nrow(freqTermsMatch)
matchPercent <- 1
unmatchedWords <- dt[!(dt$term %in% jobTerms$term),]
if(nrow(unmatchedWords)>0){
nomatch <- cbind(unmatchedWords,Freq=0)
freqTermsMatch <- rbind(freqTermsMatch,nomatch)
noMatchCount <- nrow(unmatchedWords)
matchPercent <- matchCount/(matchCount+noMatchCount)
}
freqTermsMatch <- freqTermsMatch[order(freqTermsMatch$Freq,decreasing=TRUE),]
Terms <- factor(freqTermsMatch$term)
g <- ggplot(freqTermsMatch,aes(x=term,y=Freq,fill=terms))
print(g + geom_bar(stat='identity') +
labs(title = paste0(round(matchPercent*100,1),'% match on Keywords')) +
labs(x = 'Keyword', y = 'Frequency') +
theme(plot.title = element_text(face="bold",size=18)) +
theme(axis.text.x = element_text(angle=90,face="bold",size="14")) +
theme(axis.text.y = element_text(face="bold",size="14")) +
theme(axis.title = element_text(face="bold",size="16"))
)
g <- ggplot(freqTermsMatch,aes(x=term,y=Freq,fill=Terms))
print(g + geom_bar(stat='identity') +
labs(title = paste0(round(matchPercent*100,1),'% match on Keywords')) +
labs(x = 'Keyword', y = 'Frequency') +
theme(plot.title = element_text(face="bold",size=18)) +
theme(axis.text.x = element_text(angle=90,face="bold",size="14")) +
theme(axis.text.y = element_text(face="bold",size="14")) +
theme(axis.title = element_text(face="bold",size="16"))
)
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
display.brewer.all()
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
library(shinyapps)
setwd("~/scripts/r/wordcloud")
deployApp()
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
jobInput <- "asdf"
length(jobInput)
jobInput <- ""
length(jobInput)
jobInput==""
!jobInput==""
jobInput <- "adsf"
!jobInput==""
setwd("~/scripts/r")
runApp("wordcloud")
jobInput <- reactive({input$job})
jobInput
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
library(shinyapps)
setwd("~/scripts/r/wordcloud")
deployApp()
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
library(shinyapps)
setwd("~/scripts/r/wordcloud")
deployApp()
setwd("~/scripts/r")
runApp("wordcloud")
library(shinyapps)
setwd("~/scripts/r/wordcloud")
deployApp()
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
library(shinyapps)
setwd("~/scripts/r/wordcloud")
deployApp()
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
setwd("~/scripts/r")
runApp("wordcloud")
job<- "dog walker"
clean <- gsub("[^a-zA-Z]", " ", job)
clean <- gsub(" +", " ", clean)
clean <- strsplit(clean," ")
jobTerms <- data.table(term=cbind(tolower(unlist(clean))))
setnames(jobTerms,c("term.V1"),c("term"))
# keep only terms that are not in stop words
jobTerms <- jobTerms[!(jobTerms$term %in% stopTerms$term),]
# calculate frequency of term table
freqTerms <- data.frame(xtabs(formula = ~., data = jobTerms))
wordcloud(freqTerms$term,freqTerms$Freq,scale=c(8,.2),min.freq=1,
random.order=FALSE,
rot.per=.15,colors=pal,vfont=c("serif","plain")
)
library(shiny)
library(data.table)
library(wordcloud)
library(ggplot2)
require(RColorBrewer)
pal <- brewer.pal(8,"Accent")
clean <- gsub("[^a-zA-Z]", " ", job)
clean <- gsub(" +", " ", clean)
clean <- strsplit(clean," ")
jobTerms <- data.table(term=cbind(tolower(unlist(clean))))
setnames(jobTerms,c("term.V1"),c("term"))
# keep only terms that are not in stop words
jobTerms <- jobTerms[!(jobTerms$term %in% stopTerms$term),]
# calculate frequency of term table
freqTerms <- data.frame(xtabs(formula = ~., data = jobTerms))
wordcloud(freqTerms$term,freqTerms$Freq,scale=c(8,.2),min.freq=1,
random.order=FALSE,
rot.per=.15,colors=pal,vfont=c("serif","plain")
)
job <- ""
clean <- gsub("[^a-zA-Z]", " ", job)
clean <- gsub(" +", " ", clean)
clean <- strsplit(clean," ")
jobTerms <- data.table(term=cbind(tolower(unlist(clean))))
setnames(jobTerms,c("term.V1"),c("term"))
jobTerms <- jobTerms[!(jobTerms$term %in% stopTerms$term),]
jobTerms
stopTerms <- data.table(cbind(stopWords))
setnames(stopTerms,c("stopWords"),c("term"))
stopTerms <- data.table(term=cbind(stopWords))
# source: http://norm.al/2009/04/14/list-of-english-stop-words/
stopWords <- c('a','about','above','across','after','afterwards','again','against','all','almost','alone','along',
'already','also','although','always','am','among','amongst','amoungst','amount','an','and','another',
'any','anyhow','anyone','anything','anyway','anywhere','are','around','as','at','back','be','became',
'because','become','becomes','becoming','been','before','beforehand','behind','being','below','beside',
'besides','between','beyond','bill','both','bottom','but','by','call','can','cannot','cant','co','computer',
'con','could','couldnt','cry','de','describe','detail','do','done','down','due','during','each','eg','eight',
'either','eleven','else','elsewhere','empty','enough','etc','even','ever','every','everyone','everything',
'everywhere','except','few','fifteen','fify','fill','find','fire','first','five','for','former','formerly',
'forty','found','four','from','front','full','further','get','give','go','had','has','hasnt','have','he',
'hence','her','here','hereafter','hereby','herein','hereupon','hers','him','his','how','however','hundred',
'i','ie','if','in','inc','indeed','interest','into','is','it','its','itse','keep','last','latter','latterly',
'least','less','ltd','made','many','may','me','meanwhile','might','mill','mine','more','moreover','most',
'mostly','move','much','must','my','myse','name','namely','neither','never','nevertheless','next','nine','no',
'nobody','none','noone','nor','not','nothing','now','nowhere','of','off','often','on','once','one','only','onto',
'or','other','others','otherwise','our','ours','ourselves','out','over','own','part','per','perhaps','please',
'put','rather','re','s','same','see','seem','seemed','seeming','seems','serious','several','she','should','show',
'side','since','sincere','six','sixty','so','some','somehow','someone','something','sometime','sometimes',
'somewhere','still','such','system','take','ten','than','that','the','their','them','themselves','then','thence',
'there','thereafter','thereby','therefore','therein','thereupon','these','they','thick','thin','third','this',
'those','though','three','through','throughout','thru','thus','to','together','too','top','toward','towards',
'twelve','twenty','two','un','under','until','up','upon','us','very','via','was','we','well','were','what',
'whatever','when','whence','whenever','where','whereafter','whereas','whereby','wherein','whereupon','wherever',
'whether','which','while','whither','who','whoever','whole','whom','whose','why','will','with','within','without',
'would','yet','you','your','yours','yourself','yourselves')
# stop words data table
stopTerms <- data.table(term=cbind(stopWords))
# stop words added data table for easier checking
stopTerms <- data.table(cbind(stopWords))
setnames(stopTerms,c("stopWords"),c("term"))
job <- ""
clean <- gsub("[^a-zA-Z]", " ", job)
clean <- gsub(" +", " ", clean)
clean <- strsplit(clean," ")
jobTerms <- data.table(term=cbind(tolower(unlist(clean))))
setnames(jobTerms,c("term.V1"),c("term"))
if(nrow(jobTerms)>0){
# keep only terms that are not in stop words
jobTerms <- jobTerms[!(jobTerms$term %in% stopTerms$term),]
# calculate frequency of term table
freqTerms <- data.frame(xtabs(formula = ~., data = jobTerms))
wordcloud(freqTerms$term,freqTerms$Freq,scale=c(8,.2),min.freq=1,
random.order=FALSE,
rot.per=.15,colors=pal,vfont=c("serif","plain")
)
setwd("~/scripts/r")
runApp("wordcloud")
library(shinyapps)
setwd("~/scripts/r/wordcloud")
deployApp()
setwd("~/scripts/r")
runApp("wordcloud")
library(shinyapps)
setwd("~/scripts/r/wordcloud")
deployApp()
setwd("~/scripts/r")
runApp("wordcloud")
library(shinyapps)
setwd("~/scripts/r/wordcloud")
deployApp()
library(shinyapps)
setwd("~/scripts/r/wordcloud")
deployApp()
setwd("~/scripts/r")
runApp("wordcloud")
library(shinyapps)
setwd("~/scripts/r/wordcloud")
deployApp()
setwd("~/scripts/r")
runApp("wordcloud")
library(shinyapps)
setwd("~/scripts/r/wordcloud")
deployApp()
setwd("~/scripts/r")
library(shiny)
setwd("~/scripts/r")
runApp("jobwordcloud")
runApp("jobwordcloud")
library(shinyapps)
setwd("~/scripts/r/jobwordcloud")
deployApp()
install.packages("devtools")
install_github("slidify","ramnathv")
library(devtools)
install_github("slidify","ramnathv")
install_github("slidifyLibraries","ramnathv")
library(slidify
source('~/.active-rstudio-document', echo=TRUE)
library(slidify)
setwd('~/courses/developing data products/testDeck/')
setwd('~/courses/developing data products/testDeck')
setwd('~Courses/developing data products/testDeck')
setwd('~/Documents/Courses/Developing Data Products/testDeck')
getwd()
slidify('index.Rmd')
slidify('index.Rmd')
slidify('index.Rmd')
slidify('index.Rmd')
library(knitr)
browseUrl('index.html')
browseURL('index.html')
browseURL('index.html')
library(slidify)
browseURL('index.html')
browseURL('http://google.com')
library(knitr)
browseURL('index.html')
libary(wordcloud)
require(RColorBrewer)
pal <- brewer.pal(8,"Accent")
terms <- c('job', 'data', 'analytics')
freq <- c(10,6,2)
wordcloud(terms,freq,scale=c(8,.2),min.freq=1,
random.order=FALSE,
rot.per=.15,colors=pal,vfont=c("serif","plain")
)
library(wordcloud)
require(RColorBrewer)
pal <- brewer.pal(8,"Accent")
terms <- c('job', 'data', 'analytics')
freq <- c(10,6,2)
wordcloud(terms,freq,scale=c(8,.2),min.freq=1,
random.order=FALSE,
rot.per=.15,colors=pal,vfont=c("serif","plain")
)
library(wordcloud)
require(RColorBrewer)
pal <- brewer.pal(8,"Accent")
terms <- c('job', 'data', 'analytics','future','visualize')
freq <- c(10,6,2,4,8)
wordcloud(terms,freq,scale=c(8,.2),min.freq=1,
random.order=FALSE,
rot.per=.15,colors=pal,vfont=c("serif","plain")
)
library(wordcloud)
library(Rcpp)
library(RColorBrewer)
require(RColorBrewer)
library(RColorBrewer)
library(wordcloud)
library(Rcpp)
pal <- brewer.pal(8,"Accent")
terms <- c('job', 'visualize', 'data','future')
freq <- c(4,6,2,1)
wordcloud(terms,freq,scale=c(4,.1),min.freq=1,
random.order=FALSE,
rot.per=.15,colors=pal,vfont=c("serif","plain")
)
library(RColorBrewer); library(wordcloud); library(Rcpp)
wordcloud(c('job', 'visualize', 'data','future'),
c(4,6,2,1),scale=c(4,.1),
min.freq=1,random.order=FALSE,rot.per=.15,colors=brewer.pal(8,"Accent"),
vfont=c("serif,"plain)
)
library(RColorBrewer); library(wordcloud); library(Rcpp)
wordcloud(c('job', 'visualize', 'data','future'),
c(4,6,2,1),scale=c(4,.1),
min.freq=1,random.order=FALSE,rot.per=.15,colors=brewer.pal(8,"Accent"),
vfont=c("serif,"plain)
library(RColorBrewer); library(wordcloud); library(Rcpp)
wordcloud(c('job', 'visualize', 'data','future'),
c(4,6,2,1),scale=c(4,.1),
min.freq=1,random.order=FALSE,rot.per=.15,colors=brewer.pal(8,"Accent"),
vfont=c("serif,"plain)
))
library(RColorBrewer); library(wordcloud); library(Rcpp)
wordcloud(c('job', 'visualize', 'data','future'),c(4,6,2,1),scale=c(4,.1),
min.freq=1,random.order=FALSE,rot.per=.15,colors=brewer.pal(8,"Accent"),
vfont=c("serif,"plain))
library(RColorBrewer); library(wordcloud); library(Rcpp)
wordcloud(c('job', 'visualize', 'data','future'),c(4,6,2,1),scale=c(4,.1),
min.freq=1,random.order=FALSE,rot.per=.15,colors=brewer.pal(8,"Accent"),
vfont=c("serif,"plain"))
library(RColorBrewer); library(wordcloud); library(Rcpp)
wordcloud(c('job', 'visualize', 'data','future'),c(4,6,2,1),scale=c(4,.1),
min.freq=1,random.order=FALSE,rot.per=.15,colors=brewer.pal(8,"Accent"),
vfont=c("serif,"plain"))
library(RColorBrewer); library(wordcloud); library(Rcpp)
wordcloud(c('job', 'visualize', 'data','future'),c(4,6,2,1),scale=c(4,.1),
min.freq=1,random.order=FALSE,rot.per=.15,colors=brewer.pal(8,"Accent"),
vfont=c("serif","plain"))
library(RColorBrewer); library(wordcloud); library(Rcpp); require(Rcpp)
wordcloud(c('job', 'visualize', 'data','future'),c(4,3,2,1),scale=c(6,.2),
min.freq=1,random.order=FALSE,rot.per=.15,colors=brewer.pal(8,"Accent"),
vfont=c("serif","plain"))
keywords<-c("data","scientist","scrappy","shiny","slidify")
freqTerms <- data.frame(terms=c('visualize','your','future','job','data'),freq=c(4,2,3,4,5))
View(freqTerms)
keywords <- c('data','shiny')
freqTerms <- data.frame(term=c('visualize','your','future','job','data'),freq=c(4,2,3,4,5))
keywords <- data.table(term=c('data','shiny'))
library(data.table)
library(ggplot2)
freqTerms <- data.frame(term=c('visualize','your','future','job','data'),freq=c(4,2,3,4,5))
keywords <- data.table(term=c('data','shiny'))
View(freqTerms)
View(keywords)
library(data.table)
library(ggplot2)
freqTerms <- data.frame(term=c('visualize','your','future','job','data'),freq=c(4,2,3,4,5))
dt <- data.table(term=c('data','shiny'))
dt$match <- 0
# if term is in Job Description, set to 1
dt[dt$term %in% jobTerms$term,match:=1]
# matches
freqTermsMatch <- merge(dt,freqTerms,by="term")
# see what % of keywords matched the job description
matchCount <- nrow(freqTermsMatch)
if(matchCount>0) matchPercent <- 1 else matchPercent <- 0
# unmatched keyword
unmatchedWords <- dt[!(dt$term %in% jobTerms$term),]
if(nrow(unmatchedWords)>0){
nomatch <- cbind(unmatchedWords,Freq=0)
freqTermsMatch <- rbind(freqTermsMatch,nomatch)
noMatchCount <- nrow(unmatchedWords)
matchPercent <- matchCount/(matchCount+noMatchCount)
}
freqTermsMatch <- freqTermsMatch[order(freqTermsMatch$Freq,decreasing=TRUE),]
library(data.table)
library(ggplot2)
freqTerms <- data.frame(term=c('visualize','your','future','job','data'),freq=c(4,2,3,4,5))
dt <- data.table(term=c('data','shiny'))
dt$match <- 0
# if term is in Job Description, set to 1
dt[dt$term %in% freqTerms$term,match:=1]
# matches
freqTermsMatch <- merge(dt,freqTerms,by="term")
# see what % of keywords matched the job description
matchCount <- nrow(freqTermsMatch)
if(matchCount>0) matchPercent <- 1 else matchPercent <- 0
# unmatched keyword
unmatchedWords <- dt[!(dt$term %in% freqTerms$term),]
if(nrow(unmatchedWords)>0){
nomatch <- cbind(unmatchedWords,Freq=0)
freqTermsMatch <- rbind(freqTermsMatch,nomatch)
noMatchCount <- nrow(unmatchedWords)
matchPercent <- matchCount/(matchCount+noMatchCount)
}
freqTermsMatch <- freqTermsMatch[order(freqTermsMatch$Freq,decreasing=TRUE),]
library(ggplot2)
freqTermsMatch <- data.frame(term=c('data','shiny'),Freq=c(1,0))
g <- ggplot(freqTermsMatch,aes(x=term,y=Freq))
print(g + geom_bar(stat='identity') +
labs(title = paste0(round(.5*100,1),'% match on Keywords')) +
labs(x = 'Keyword', y = 'Frequency') +
theme(plot.title = element_text(face="bold",size=18)) +
theme(axis.text.x = element_text(angle=90,face="bold",size="14")) +
theme(axis.text.y = element_text(face="bold",size="14")) +
theme(axis.title = element_text(face="bold",size="16"))
)
library(slidify)
publish(user = "aliciatb", repo = "testDeck")
library(png)
library(grid)
img <- readPNG("assets/img/jobwordcloud.jpg")
grid.raster(img)
install.packages("png")
install.packages("grid")
install.packages("grid")
install.packages("grid")
install.packages("grid")
install.packages("grid")
library(png)
library(grid)
img <- readPNG("assets/img/jobwordcloud.jpg")
library(png)
library(grid)
img <- readPNG("assets/img/jobwordcloud.png")
grid.raster(img)
img <- readPNG("assets/img/jobwordcloud.png")
grid.raster(img, width=10, height=10)
grid.raster(img)
<img src="assets/img/jobwordcloud.jpg" height=100>  _Theodore Roosevelt, 26th President of the United States_
[Visualize your next job Shiny App](https://alicia.shinyapps.io/jobwordcloud/)
library(png)
library(grid)
img <- readPNG("assets/img/jobwordcloud.png")
grid.raster(img)
library(png)
library(grid)
img <- readPNG("assets/img/jobwordcloud.png")
grid.raster(img)
